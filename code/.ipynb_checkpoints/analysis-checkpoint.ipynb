{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import os\n",
    "import re\n",
    "\n",
    "from scipy import stats\n",
    "from subprocess import check_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods to import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods To Import Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "this function will take as an argument a file containing\n",
    "the field index and description for every field in the data frames.\n",
    "I will use this to create a template dataframe and to name the columns\n",
    "because currently it is just using the first value as the column name\n",
    "and it makes literally no sense at all.\n",
    "'''\n",
    "def shape_ev_data():\n",
    "    #this file contains all the field descriptions\n",
    "    field_descriptor_file_path = \"csvFieldDescriptions.txt\"\n",
    "    \n",
    "    #open the file and read it, adding each description to a list\n",
    "    fields = open(field_descriptor_file_path, 'r')\n",
    "    fieldInfo = []\n",
    "    for field in fields:\n",
    "        fieldInfo.append(field[2:].strip())\n",
    "    fields.close() #close file\n",
    "    return fieldInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes as an argument the number of subframes to include\n",
    "where each 'subframe' is a pandas data frame containing play by play\n",
    "data for a team for a year. It will then return those subframes\n",
    "concatenated together into one main data frame. Subframes is preset to 50\n",
    "'''\n",
    "def get_event_data(subframes=50):\n",
    "    csvFiles = '../data/event_csv_files/'\n",
    "    csv_paths = os.listdir(csvFiles)#Get the paths of all of the CSV files\n",
    "    column_info = shape_ev_data()#get the information on each field\n",
    "    data = pd.DataFrame(columns=column_info)#create an empty data frame\n",
    "    individual_data = []#create a list to hold the smaller frames\n",
    "    del individual_data[:]#clear the list just in case I've already been using it\n",
    "\n",
    "    #make all the dataframes\n",
    "    df = pd.DataFrame(columns=column_info) #define a temp frame\n",
    "    for index, path in enumerate(csv_paths):#iterate over the list of paths\n",
    "        #names=column_info is what names the columns\n",
    "        df = pd.read_csv(str(csvFiles+path), names=column_info)#read a file into a csv\n",
    "        individual_data.append(df)#add it to the list\n",
    "        \n",
    "        #this line here is what limits how much data you pull.\n",
    "        #if you eneter -1 for subframes it'll skip this check and\n",
    "        #generate all of the data\n",
    "        if(subframes != -1):#if the passed parameter is -1, generate ALL data\n",
    "            if(index==subframes):#stop when desired subframe # is reached\n",
    "                break\n",
    "    \n",
    "    data = pd.concat(individual_data) #combining sub frames\n",
    "    del individual_data[:] #dont wanna waste space\n",
    "    return data#, individual_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method To Import Game Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in all the game logs and appending the dataframe accordingly\n",
    "def get_gl_data():\n",
    "    GLData = pd.DataFrame()\n",
    "    gls = [] #to hold smaller frames\n",
    "    del gls[:] #clear it to be sure\n",
    "    glogpath = '../data/GameLogs/' #path to the game logs\n",
    "    headPath = glogpath+'game_log_header.csv' #get the column info\n",
    "    header = pd.read_csv(headPath) #import the column info\n",
    "    colInfo = header.columns #store it for later use\n",
    "    start_year = 1950 #define starting year. gonna use this in path\n",
    "    end_year = 17 #also for path\n",
    "    for logFolder in os.listdir(glogpath):\n",
    "        try:#catching non int cases\n",
    "            y1 = int(logFolder[2:4]) ##first two of start yyyy\n",
    "            y2 = int(logFolder[2:6]) ##full start year\n",
    "            y3 = int(str(y1)+logFolder[-2:]) #full end year\n",
    "        except:\n",
    "            continue\n",
    "        #now open the folder if the start year is between the dates in the name\n",
    "        if(start_year<y3):\n",
    "            newPath = glogpath+logFolder\n",
    "            files = os.listdir(newPath)#get all the logs in the folder\n",
    "            for file in files:#now check each file to make sure it's the righ year\n",
    "                year = int(file[2:6])#get year of file\n",
    "                if(year>=start_year):#if it's within the range we want\n",
    "                    full_path = glogpath+logFolder+'/'+file #make full path\n",
    "                    gls.append(pd.read_csv(full_path, names=colInfo))#append the frame\n",
    "    GLData = pd.concat(gls) #combine the subframes into this one\n",
    "    del gls[:] #not wasting space\n",
    "    return GLData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method To Import Park Information Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this method will return an unedited dataframe of the park information\n",
    "def get_park_data():\n",
    "    parks = pd.DataFrame() #create empty frame\n",
    "    path = '../data/ParkInfo/ParkCodes.TXT' #path to park data\n",
    "\n",
    "    cols = ['PARKID','CITY','STATE'] #cols to import\n",
    "    parks = pd.read_csv(path, usecols=cols) #import it as csv\n",
    "    parks.columns = ['parkid','city','state'] #name cols\n",
    "    parks['location'] = parks.city + ', ' + parks.state #easier to cross ref\n",
    "    parks = parks.drop(['city','state'],axis=1)\n",
    "    \n",
    "    #parks['lat'] = 0\n",
    "    #parks['lng'] = 0\n",
    "    \n",
    "    return parks #return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method To Import City Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this method imports data on cities in the us\n",
    "def get_ct_data():\n",
    "    cities = pd.DataFrame() #create empty frame\n",
    "    path = '../data/ParkInfo/uscities.csv' #path\n",
    "    \n",
    "    #which columns to import\n",
    "    cols = ['city','state_id','lat','lng',]\n",
    "    \n",
    "    #get park info but only read the cols i want\n",
    "    cities = pd.read_csv(path, usecols=cols)\n",
    "    \n",
    "    cities.columns = ['city','state','lat','lng'] #rename cols\n",
    "    cities['location'] = cities.city + ', ' + cities.state #for cross ref\n",
    "    cities = cities.drop(['city','state'], axis=1) #drop old cols\n",
    "    \n",
    "    cities = cities.drop_duplicates(subset='location') #only one station per city\n",
    "    \n",
    "    return cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method To Import Station Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the station data\n",
    "def get_st_data():\n",
    "    cols = ['id','lat','lng','elevation','state']\n",
    "    stations = pd.DataFrame(columns=cols) #stations\n",
    "    path = '../data/Weather/station_list.txt' #path to file\n",
    "    formatted_path = '../data/Weather/formatted_station_list.txt'\n",
    "    stations = open(path, 'r') #open weather stations\n",
    "    f_stations = open(formatted_path,'w') #file to write to\n",
    "    \n",
    "    #reformat the weather station file so it's not this ridiculous format\n",
    "    for line in stations: #for each line\n",
    "        new = line[:41] #remove the end because that's all irrelevant\n",
    "        new = re.sub('\\s\\s$', 'zz', new)#fake state col if it doesn't exist\n",
    "        new = ','.join(new.split())#remove spaces and replace with commas\n",
    "        new = new+'\\n' #add a newline at the end\n",
    "        f_stations.write(new) #write the formatted line\n",
    "    f_stations.close() #close the file at the end\n",
    "    \n",
    "    #now set stations frame\n",
    "    stations = pd.read_csv(formatted_path, names=cols)\n",
    "    \n",
    "    stations = stations.replace('zz',np.nan)#replace the zz\n",
    "    stations = stations.dropna(subset=['state'],axis=0)#drop ones with state (not in us)\n",
    "    \n",
    "    return stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method To Import bgame Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get cols of feature names for bgame files\n",
    "def shape_gl_data():\n",
    "    fn = open('bgameFeatureNames.TXT', 'r') #open file\n",
    "    fnames = [] #to store names\n",
    "    for feature in fn: #go over lines\n",
    "        f = re.sub('[\\(\\[].*?[\\)\\]]', '', feature[5:]).strip() #strip it\n",
    "        fnames.append(f) #add to list\n",
    "    fn.close()#close file\n",
    "    return fnames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gets game log data from bgame\n",
    "def get_gl2_data():\n",
    "    csvFiles = '../data/game_csv_files/'\n",
    "    csv_paths = os.listdir(csvFiles)#Get the paths of all of the CSV files\n",
    "    column_info = shape_gl_data()#get the information on each field\n",
    "    data = pd.DataFrame(columns=column_info)#create an empty data frame\n",
    "    individual_data = []#create a list to hold the smaller frames\n",
    "    del individual_data[:]#clear the list just in case I've already been using it\n",
    "\n",
    "    #make all the dataframes\n",
    "    df = pd.DataFrame(columns=column_info) #define a temp frame\n",
    "    for index, path in enumerate(csv_paths):#iterate over the list of paths\n",
    "        #names=column_info is what names the columns\n",
    "        df = pd.read_csv(str(csvFiles+path), names=column_info)#read a file into a csv\n",
    "        individual_data.append(df)#add it to the list\n",
    "    \n",
    "    data = pd.concat(individual_data) #combining sub frames\n",
    "    del individual_data[:] #dont wanna waste space\n",
    "    return data#, individual_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should probably turn these into functions so I can also preprocess the main dataset. or any of the data that I want to pass to it. Shouldn't be to hard to parameterize. I guess it's worth noting that all of these functions so far have been written with the event data in mind. They almost certainly will not work on the gamelog data. I'm gonna rename the functions to indicate what data they should be used on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to see what fraction of the original size the pruned data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this will just return how much memory pre, post and the percentage\n",
    "def get_reduction(pre, post):\n",
    "    a = np.sum(pre.memory_usage())\n",
    "    b = np.sum(post.memory_usage())\n",
    "    return a, b, b/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to drop a lot of columns\n",
    "def prune_ev_data(original_data, verbose=False):\n",
    "    #indexes for columns to drop. Honestly i just looked at the field descriptions\n",
    "    #and dropped mostly things like who was playing each position, where the ball \n",
    "    #was hit, the names of people who contributed to the play, etc\n",
    "    ix = [12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 46, 47,\n",
    "          49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
    "          67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86,\n",
    "          87, 88, 89, 90, 91, 92, 93, 94, 95, 96\n",
    "         ]\n",
    "    #gonna turn those indexes into names just to ensure i drop the right\n",
    "    #columns\n",
    "    ixn = original_data.columns[ix]\n",
    "    \n",
    "    #verbose option\n",
    "    if(verbose):\n",
    "        print(\"Dropping Columns:\\n\")\n",
    "        for col in ixn:\n",
    "            print(col)\n",
    "    \n",
    "    pruned_data = original_data #copy data for pruned data\n",
    "    #original_data_size = np.sum(original_data.memory_usage(deep=True)) #how big is the data\n",
    "\n",
    "    #Prune Columns\n",
    "    pruned_data = pruned_data.drop(pruned_data.columns[ix], axis=1) #prune columns\n",
    "    \n",
    "    return pruned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prune the game logs\n",
    "def prune_gl_data(original_data, verbose=False):\n",
    "    #columns to drop. Doing by index again because it'd be a huge hassle to\n",
    "    #type hundreds of column names. I will convert the indices to col namse\n",
    "    #and add a verbose flag to see what I've chosen to drop. Again,\n",
    "    #i'm basically just reading the data description on retrosheet and doing\n",
    "    #this by hand. In the future, it would be easier to only pull the data we \n",
    "    #need as opposed to pulling all and then pruning\n",
    "    #gonna use lists to get ranges so i don't have to type tons of nums\n",
    "    ix = [13, 14, 15, 4, 5, 7, 8]\n",
    "    l1 = list(np.arange(78, 101, 1))\n",
    "    l2 = list(np.arange(106, 161, 1))\n",
    "    ix  = ix + l1 + l2 #concat these lists\n",
    "    \n",
    "    #get col names\n",
    "    ixn = original_data.columns[ix]\n",
    "    \n",
    "    #verbose option\n",
    "    if(verbose):\n",
    "        print(\"Dropping Columns:\\n\")\n",
    "        for col in ixn:\n",
    "            print(col)\n",
    "    \n",
    "    pruned_data = original_data #copy data for pruned data\n",
    "    \n",
    "    #Prune Columns\n",
    "    pruned_data = pruned_data.drop(pruned_data.columns[ix], axis=1) #prune columns\n",
    "    \n",
    "    return pruned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this method takes the event data and, for each event, adds a column for the\n",
    "#team under which the play is filed, the date of the play (for weather)\n",
    "#and the game of the day\n",
    "def add_ev_metadata(event_data):\n",
    "    #Adding in a bit more data on the team, date, game of day, and also field\n",
    "    event_data['team'] = event_data['game id'].astype(str).str[:3]#storing the team\n",
    "    event_data['date'] = event_data['game id'].astype(str).str[3:-1]#date\n",
    "    event_data['game_of_day'] = event_data['game id'].astype(str).str[-1:]#which game of the day it is\n",
    "    return event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in park data, city data, and station data respectively.\n",
    "#adds the coordinates and respective weather station to each park entry\n",
    "def add_pk_metadata(pdata, cdata, sdata):\n",
    "    #adding coordinates\n",
    "    pdata = pdata.merge(cdata, left_on='location', right_on='location', how='left')\n",
    "    \n",
    "    #now find the nearest weather station\n",
    "    pdata['station'] = 'na'#create an empty station col\n",
    "    combined = pd.DataFrame() #empty combined frame\n",
    "    \n",
    "    #just giving it a parkid to use as a placeholder\n",
    "    sdata['parkid'] = 'zz'\n",
    "    \n",
    "    #defining the columns of the new frame\n",
    "    #combining park and station data\n",
    "    ids = pdata['parkid'].append(sdata['parkid'], ignore_index=True) #add this to frame\n",
    "    lats = pdata['lat'].append(sdata['lat'], ignore_index=True) #add latitudes\n",
    "    lngs = pdata['lng'].append(sdata['lng'], ignore_index=True) #and lngs\n",
    "    stations = pdata['station'].append(sdata['id'], ignore_index=True) #adding a station col\n",
    "    \n",
    "    #adding these to the combined frame\n",
    "    combined['lng'] = lngs\n",
    "    combined['lat'] = lats\n",
    "    combined['parkid'] = ids\n",
    "    combined['station'] = stations\n",
    "    \n",
    "    print(pdata.head())\n",
    "    \n",
    "    return pdata\n",
    "    \n",
    "    #gonna use a nearest neighbors algorithm that uses lat and long\n",
    "    #to find the single nearest neighbor to each point.\n",
    "    #will use the combined cities and stations data so that it matches\n",
    "    #a city with the nearest station. I'm using cities because there are multiple\n",
    "    #parks per city, so they would just match with each other instead of a station.\n",
    "    X = np.column_stack((combined['lat'],combined['lng']))\n",
    "    nbrs = NearestNeighbors(n_neighbors=2).fit(X)\n",
    "    \n",
    "    #only want to find the neighbors for the parks \n",
    "    #this is the first 252 rows\n",
    "    X2 = X[:252]\n",
    "    \n",
    "    #get the distances and indices\n",
    "    d, i  = nbrs.kneighbors(X)\n",
    "    \n",
    "    pairs = [] #pairs of indices for cities and stations in the combined frame\n",
    "    for r in i: #for each set of neighbors\n",
    "        found = False #if the best match hasn't been found\n",
    "        for ix in r: #check each of the best pairs\n",
    "            if(found): #if the best neighbor has been found break\n",
    "                break\n",
    "            if(ix>=252 and not found): #if the neighbor is NOT another city\n",
    "                pairs.append([r[0],ix]) #add the pair\n",
    "                found = True #mark that a station has been found\n",
    "    \n",
    "    return pdata, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  parkid       location      lat       lng station\n",
      "0  ALB01     Albany, NY  42.6664  -73.7987      na\n",
      "1  ALT01    Altoona, PA  40.5084  -78.4010      na\n",
      "2  ANA01    Anaheim, CA  33.8390 -117.8572      na\n",
      "3  ARL01  Arlington, TX  32.6998  -97.1251      na\n",
      "4  ARL02  Arlington, TX  32.6998  -97.1251      na\n"
     ]
    }
   ],
   "source": [
    "pkdata2 = add_pk_metadata(pkdata, ctdata, stdata)\n",
    "#pkdata2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pkdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6c0bf95e9fb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#adding coordinates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpkdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'location'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'location'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#now find the nearest weather station\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpkdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'station'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'na'\u001b[0m\u001b[1;31m#create an empty station col\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pkdata' is not defined"
     ]
    }
   ],
   "source": [
    "#adding coordinates\n",
    "pkdata = pkdata.merge(ctdata, left_on='location', right_on='location', how='left')\n",
    "\n",
    "#now find the nearest weather station\n",
    "pkdata['station'] = 'na'#create an empty station col\n",
    "\n",
    "combined = pd.DataFrame() #empty combined frame\n",
    "stdata['parkid'] = 'zz' #so i can add them to the frame and it's easier to separate\n",
    "\n",
    "lngs = pkdata['lng'].append(stdata['lng'], ignore_index=True) #and lngs\n",
    "locations = pkdata['parkid'].append(stdata['parkid'], ignore_index=True) #add this to frame\n",
    "lats = pkdata['lat'].append(stdata['lat'], ignore_index=True) #add latitudes\n",
    "\n",
    "combined['lat'] = lats\n",
    "combined['lng'] = lngs\n",
    "combined['locations'] = locations\n",
    "\n",
    "\n",
    "\n",
    "#gonna use a nearest neighbors algorithm that uses lat and long\n",
    "#to find the single nearest neighbor to each point.\n",
    "#will use the combined cities and stations data so that it matches\n",
    "#a city with the nearest station. I'm using cities because there are multiple\n",
    "#parks per city, so they would just match with each other instead of a station.\n",
    "X = np.column_stack((combined['lat'],combined['lng']))\n",
    "#nbrs = NearestNeighbors(n_neighbors=4).fit(X)\n",
    "\n",
    "X2 = X[:252]\n",
    "\n",
    "#d, i  = nbrs.kneighbors(X2)\n",
    "#print(i[:36][:])\n",
    "#pairs = []\n",
    "#for r in i:\n",
    "#    found = False\n",
    "#    for ix in r:\n",
    "#        if(found):\n",
    "#            break\n",
    "#        if(ix>=252 and not found):\n",
    "#            pairs.append([r[0],ix])\n",
    "#            found = True\n",
    "            \n",
    "pkdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Categorical Data to Ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes any categorical data that can be represented as\n",
    "#ints and converts it. it also reduces all int columns\n",
    "#to the smallest possible integer form\n",
    "def reduce_ev_nums(original_data):\n",
    "    redata = original_data #reduced event data\n",
    "\n",
    "    #I noticed all the features I wanted to convert were all binary data for\n",
    "    #flags and which hand people use. So gonna iterate through the features\n",
    "    #and convert features with the word flag or hand\n",
    "    for column in redata.columns:#go through the cols\n",
    "        #if the feature name has hand or flag\n",
    "        if(('hand' in column.lower()) or ('flag' in column.lower())):\n",
    "            redata[column] = redata[column].astype('category')#set to cat\n",
    "\n",
    "    #convert them to ints            \n",
    "    cat_columns = redata.select_dtypes(['category']).columns #get cat cols\n",
    "    redata[cat_columns] = redata[cat_columns].apply(lambda x: x.cat.codes) #cast to int\n",
    "    \n",
    "    #downcast all to smallest acceptable int size\n",
    "    ints = redata.select_dtypes(include=['int']) #get any int cols\n",
    "    ints = ints.apply(pd.to_numeric, downcast='unsigned') #downcast them\n",
    "    \n",
    "    #downcast floats\n",
    "    floats = redata.select_dtypes(include=['float']) #get floats\n",
    "    floats = floats.apply(pd.to_numeric,downcast='float') #downcast them\n",
    "    \n",
    "    #now replace the numeric columns with their reduced ones\n",
    "    redata[ints.columns] = ints #replace with reduced ints\n",
    "    redata[floats.columns] = floats #replace with reduced floats\n",
    "    \n",
    "    #retyped_data_size = np.sum(redata.memory_usage(deep=True)) #store size\n",
    "    return redata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function will reduce the numbers in the game log data\n",
    "def reduce_gl_nums(original_data, verbose=False):\n",
    "    redata = original_data #copy data\n",
    "    \n",
    "    #manually looked through at which object cols could be cast to ints and \n",
    "    #reduced. Converting some like player name would cause us to lose info\n",
    "    #at the same time, we aren't really interested in specific pitchers so \n",
    "    #that may be a good idea to reduce them as well. future decisions.\n",
    "    ixn = ['DayOfWeek','DayNight'] #names for verbose\n",
    "    ix = [] #to store indices of names\n",
    "    for i in ixn: #iterate over col names\n",
    "        ix.append(original_data.columns.get_loc(i)) #get index from name\n",
    "    \n",
    "    #print names if verbose\n",
    "    if(verbose):\n",
    "        print(\"Removing Columns:\\n\")\n",
    "        for col in ixn:\n",
    "            print(col)\n",
    "            \n",
    "    #convert ints to categories\n",
    "    for col in ixn:\n",
    "        redata[col] = redata[col].astype('category')#cast to category\n",
    "    \n",
    "    #convert categories to ints\n",
    "    cat_cols = redata.select_dtypes(['category']).columns #get cat cols\n",
    "    redata[cat_cols] = redata[cat_cols].apply(lambda x: x.cat.codes) #to int\n",
    "    \n",
    "    #downcast ints\n",
    "    ints = redata.select_dtypes(include=['int']) #get ints\n",
    "    ints = ints.apply(pd.to_numeric,downcast='unsigned') #downcast them\n",
    "    \n",
    "    #downcast floats\n",
    "    floats = redata.select_dtypes(include=['float']) #get floats\n",
    "    floats = floats.apply(pd.to_numeric,downcast='float') #downcast them\n",
    "    \n",
    "    #now replace the numeric columns with their reduced ones\n",
    "    redata[ints.columns] = ints #replace with reduced ints\n",
    "    redata[floats.columns] = floats #replace with reduced floats\n",
    "    \n",
    "    return redata #return the reduced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function just combines the preprocessing steps so you don't have to\n",
    "# it takes a dataframe and a frame type eg: ev for event, gl for game log,\n",
    "# pk for park, wt for weather. It will then return the processed data and,\n",
    "# if you pass verbose as True, it'll return the dataframe size at each step\n",
    "# stored in a list\n",
    "def process_data(data, data_type, verbose=False):\n",
    "    sizes = [] #to store data sizes\n",
    "    reduced = pd.DataFrame() #to store reduced data\n",
    "    \n",
    "    #store first mem usage for verbose\n",
    "    sizes.append(np.sum(data.memory_usage(deep=True)))\n",
    "    \n",
    "    #process depending on data type\n",
    "    if(data_type=='ev'): #event data\n",
    "        reduced = prune_ev_data(data) #prune\n",
    "        sizes.append(np.sum(reduced.memory_usage(deep=True))) #verbose\n",
    "        reduced = reduce_ev_nums(reduced) #downcast numerics\n",
    "        sizes.append(np.sum(reduced.memory_usage(deep=True))) #verbose\n",
    "    elif(data_type=='gl'):\n",
    "        reduced = prune_gl_data(data) #prune\n",
    "        sizes.append(np.sum(reduced.memory_usage(deep=True))) #verbose\n",
    "        reduced = reduce_gl_nums(reduced) #downcast numerics\n",
    "        sizes.append(np.sum(reduced.memory_usage(deep=True))) #verbose\n",
    "    else:\n",
    "        print(\"Please enter a valid data type.\")\n",
    "        return\n",
    "    \n",
    "    #return depending on verbose\n",
    "    if(verbose): #return the sizes\n",
    "        return reduced, sizes #like so\n",
    "    else: #if they don't want verbose just return data\n",
    "        return reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Data Frames and Processing Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "evdata = get_event_data() #get event data\n",
    "gldata = get_gl_data() #get game log data\n",
    "pkdata = get_park_data() #get park data\n",
    "ctdata = get_ct_data() #get city data\n",
    "stdata = get_st_data() #get the station data\n",
    "\n",
    "gl2data = get_gl2_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is an example of how to use the process data function\n",
    "reduced_evdata = process_data(evdata, 'ev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['game id', 'date', 'game number', 'day of week', 'start time',\n",
       "       'DH used flag', 'day/night flag', 'visiting team', 'home team',\n",
       "       'game site', 'vis. starting pitcher', 'home starting pitcher',\n",
       "       'home plate umpire', 'first base umpire', 'second base umpire',\n",
       "       'third base umpire', 'left field umpire', 'right field umpire',\n",
       "       'attendance', 'PS scorer', 'translator', 'inputter', 'input time',\n",
       "       'edit time', 'how scored', 'pitches entered?', 'temperature',\n",
       "       'wind direction', 'wind speed', 'field condition', 'precipitation',\n",
       "       'sky', 'time of game', 'number of innings', 'visitor final score',\n",
       "       'home final score', 'visitor hits', 'home hits', 'visitor errors',\n",
       "       'home errors', 'visitor left on base', 'home left on base',\n",
       "       'winning pitcher', 'losing pitcher', 'save for', 'GW RBI',\n",
       "       'visitor batter 1', 'visitor position 1', 'visitor batter 2',\n",
       "       'visitor position 2', 'visitor batter 3', 'visitor position 3',\n",
       "       'visitor batter 4', 'visitor position 4', 'visitor batter 5',\n",
       "       'visitor position 5', 'visitor batter 6', 'visitor position 6',\n",
       "       'visitor batter 7', 'visitor position 7', 'visitor batter 8',\n",
       "       'visitor position 8', 'visitor batter 9', 'visitor position 9',\n",
       "       'home batter 1', 'home position 1', 'home batter 2', 'home position 2',\n",
       "       'home batter 3', 'home position 3', 'home batter 4', 'home position 4',\n",
       "       'home batter 5', 'home position 5', 'home batter 6', 'home position 6',\n",
       "       'home batter 7', 'home position 7', 'home batter 8', 'home position 8',\n",
       "       'home batter 9', 'home position 9', 'visitor finishing pitcher',\n",
       "       'home finishing pitcher', 'name of official scorer, if known'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl2data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get = ['game id','day/night flag','attendance','temperature','wind direction',\n",
    "      'wind speed','field condition','precipitation','sky']\n",
    "weather = gl2data[get]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66801, 9)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game id</th>\n",
       "      <th>batter</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>strikeouts</th>\n",
       "      <th>BA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>battm101</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>baueh101</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>berry101</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>browb105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>colej106</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>delsj101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>dimad101</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>dimaj101</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>doerb101</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>goodb101</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>henrt101</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>johnb108</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>lindj101</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>martb105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>mizej101</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>parnm101</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>peskj101</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>reyna102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>rizzp101</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>sanff101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>stepv101</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>stril101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>waked101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>willt103</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>zaria101</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>battm101</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>baueh101</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>berry101</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>browb105</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>colej106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>dimad101</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>dimaj101</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>doerb101</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>goodb101</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>henrt101</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>keltk101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>kinde101</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>lindj101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>lopae101</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>mapec101</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         game id    batter  AB    H  strikeouts        BA\n",
       "0   BOS195004180  battm101   5  0.0         5.0  0.000000\n",
       "1   BOS195004180  baueh101   4  1.0         3.0  0.250000\n",
       "2   BOS195004180  berry101   5  3.0         2.0  0.600000\n",
       "3   BOS195004180  browb105   1  0.0         1.0  0.000000\n",
       "4   BOS195004180  colej106   2  0.0         2.0  0.000000\n",
       "5   BOS195004180  delsj101   1  0.0         1.0  0.000000\n",
       "6   BOS195004180  dimad101   5  2.0         3.0  0.400000\n",
       "7   BOS195004180  dimaj101   6  3.0         3.0  0.500000\n",
       "8   BOS195004180  doerb101   4  3.0         1.0  0.750000\n",
       "9   BOS195004180  goodb101   4  1.0         3.0  0.250000\n",
       "10  BOS195004180  henrt101   6  2.0         4.0  0.333333\n",
       "11  BOS195004180  johnb108   4  2.0         2.0  0.500000\n",
       "12  BOS195004180  lindj101   2  1.0         1.0  0.500000\n",
       "13  BOS195004180  martb105   2  2.0         0.0  1.000000\n",
       "14  BOS195004180  mizej101   1  1.0         0.0  1.000000\n",
       "15  BOS195004180  parnm101   2  0.0         2.0  0.000000\n",
       "16  BOS195004180  peskj101   5  2.0         3.0  0.400000\n",
       "17  BOS195004180  reyna102   1  0.0         1.0  0.000000\n",
       "18  BOS195004180  rizzp101   4  0.0         4.0  0.000000\n",
       "19  BOS195004180  sanff101   1  0.0         1.0  0.000000\n",
       "20  BOS195004180  stepv101   6  3.0         3.0  0.500000\n",
       "21  BOS195004180  stril101   1  0.0         1.0  0.000000\n",
       "22  BOS195004180  waked101   1  0.0         1.0  0.000000\n",
       "23  BOS195004180  willt103   3  2.0         1.0  0.666667\n",
       "24  BOS195004180  zaria101   5  2.0         3.0  0.400000\n",
       "25  BOS195004192  battm101   4  0.0         4.0  0.000000\n",
       "26  BOS195004192  baueh101   1  1.0         0.0  1.000000\n",
       "27  BOS195004192  berry101   6  1.0         5.0  0.166667\n",
       "28  BOS195004192  browb105   3  0.0         3.0  0.000000\n",
       "29  BOS195004192  colej106   3  3.0         0.0  1.000000\n",
       "30  BOS195004192  dimad101   4  2.0         2.0  0.500000\n",
       "31  BOS195004192  dimaj101   6  3.0         3.0  0.500000\n",
       "32  BOS195004192  doerb101   4  2.0         2.0  0.500000\n",
       "33  BOS195004192  goodb101   4  2.0         2.0  0.500000\n",
       "34  BOS195004192  henrt101   4  3.0         1.0  0.750000\n",
       "35  BOS195004192  keltk101   1  0.0         1.0  0.000000\n",
       "36  BOS195004192  kinde101   2  0.0         2.0  0.000000\n",
       "37  BOS195004192  lindj101   1  0.0         1.0  0.000000\n",
       "38  BOS195004192  lopae101   3  2.0         1.0  0.666667\n",
       "39  BOS195004192  mapec101   5  2.0         3.0  0.400000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe with data to calculate batting average\n",
    "oBatterData = reduced_evdata[['game id', 'batter', 'event type', 'batter event flag', 'ab flag', 'hit value']].copy()\n",
    "\n",
    "# Calculate batters' at bats and hits per game\n",
    "BatterData = oBatterData.loc[(oBatterData['batter event flag'] == 1) & (oBatterData['ab flag'] == 1)]\n",
    "BatterData2 = BatterData.loc[(BatterData['batter event flag'] == 1) & (BatterData['ab flag'] == 1) & (BatterData['hit value'] > 0)]\n",
    "BatterData = BatterData.groupby(['game id', 'batter']).size().reset_index(name='AB')\n",
    "BatterData2 = BatterData2.groupby(['game id', 'batter']).size().reset_index(name='H')\n",
    "\n",
    "#BatterData.loc[(BatterData['batter event flag'] == 1) & (BatterData['ab flag'] == 1)]['hit value'].groupby(['batter'])\n",
    "\n",
    "BatterData3 = oBatterData.loc[(oBatterData['batter event flag'] == 1) & (oBatterData['ab flag'] == 1) & (oBatterData['hit value'] == 0)]\n",
    "BatterData3 = BatterData3.groupby(['game id', 'batter']).size().reset_index(name='strikeouts')\n",
    "\n",
    "bat3 = BatterData.merge(BatterData2, left_on=['batter','game id'], right_on=['batter','game id'], how='outer')\n",
    "bat3 = bat3.merge(BatterData3, left_on=['batter','game id'], right_on=['batter','game id'], how='outer')\n",
    "\n",
    "bat3['BA'] = bat3.apply(lambda row: row['H']/row['AB'],axis=1)\n",
    "\n",
    "bat3 = bat3.fillna(value=0, axis=1)\n",
    "\n",
    "bat3.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game id</th>\n",
       "      <th>date</th>\n",
       "      <th>game number</th>\n",
       "      <th>day of week</th>\n",
       "      <th>start time</th>\n",
       "      <th>DH used flag</th>\n",
       "      <th>day/night flag</th>\n",
       "      <th>visiting team</th>\n",
       "      <th>home team</th>\n",
       "      <th>game site</th>\n",
       "      <th>...</th>\n",
       "      <th>home position 6</th>\n",
       "      <th>home batter 7</th>\n",
       "      <th>home position 7</th>\n",
       "      <th>home batter 8</th>\n",
       "      <th>home position 8</th>\n",
       "      <th>home batter 9</th>\n",
       "      <th>home position 9</th>\n",
       "      <th>visitor finishing pitcher</th>\n",
       "      <th>home finishing pitcher</th>\n",
       "      <th>name of official scorer, if known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS195004180</td>\n",
       "      <td>500418</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>NYA</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS07</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>goodb101</td>\n",
       "      <td>3</td>\n",
       "      <td>battm101</td>\n",
       "      <td>2</td>\n",
       "      <td>parnm101</td>\n",
       "      <td>1</td>\n",
       "      <td>pagej101</td>\n",
       "      <td>ferrd101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS195004192</td>\n",
       "      <td>500419</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>NYA</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS07</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>zaria101</td>\n",
       "      <td>9</td>\n",
       "      <td>battm101</td>\n",
       "      <td>2</td>\n",
       "      <td>kinde101</td>\n",
       "      <td>1</td>\n",
       "      <td>pagej101</td>\n",
       "      <td>schac101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS195004280</td>\n",
       "      <td>500428</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>PHA</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS07</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>obrit103</td>\n",
       "      <td>8</td>\n",
       "      <td>tebbb101</td>\n",
       "      <td>2</td>\n",
       "      <td>parnm101</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS195004301</td>\n",
       "      <td>500430</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>PHA</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS07</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>goodb101</td>\n",
       "      <td>3</td>\n",
       "      <td>tebbb101</td>\n",
       "      <td>2</td>\n",
       "      <td>dobsj101</td>\n",
       "      <td>1</td>\n",
       "      <td>shanb102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS195004302</td>\n",
       "      <td>500430</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>PHA</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS07</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>goodb101</td>\n",
       "      <td>3</td>\n",
       "      <td>battm101</td>\n",
       "      <td>2</td>\n",
       "      <td>stobc101</td>\n",
       "      <td>1</td>\n",
       "      <td>schec101</td>\n",
       "      <td>papaa101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        game id    date  game number day of week  start time DH used flag  \\\n",
       "0  BOS195004180  500418            0     Tuesday           0            F   \n",
       "1  BOS195004192  500419            2   Wednesday           0            F   \n",
       "2  BOS195004280  500428            0      Friday           0            F   \n",
       "3  BOS195004301  500430            1      Sunday           0            F   \n",
       "4  BOS195004302  500430            2      Sunday           0            F   \n",
       "\n",
       "  day/night flag visiting team home team game site  \\\n",
       "0              D           NYA       BOS     BOS07   \n",
       "1              D           NYA       BOS     BOS07   \n",
       "2              D           PHA       BOS     BOS07   \n",
       "3              D           PHA       BOS     BOS07   \n",
       "4              D           PHA       BOS     BOS07   \n",
       "\n",
       "                 ...                home position 6 home batter 7  \\\n",
       "0                ...                              4      goodb101   \n",
       "1                ...                              3      zaria101   \n",
       "2                ...                              7      obrit103   \n",
       "3                ...                              9      goodb101   \n",
       "4                ...                              9      goodb101   \n",
       "\n",
       "  home position 7 home batter 8 home position 8 home batter 9 home position 9  \\\n",
       "0               3      battm101               2      parnm101               1   \n",
       "1               9      battm101               2      kinde101               1   \n",
       "2               8      tebbb101               2      parnm101               1   \n",
       "3               3      tebbb101               2      dobsj101               1   \n",
       "4               3      battm101               2      stobc101               1   \n",
       "\n",
       "  visitor finishing pitcher  home finishing pitcher  \\\n",
       "0                  pagej101                ferrd101   \n",
       "1                  pagej101                schac101   \n",
       "2                       NaN                     NaN   \n",
       "3                  shanb102                     NaN   \n",
       "4                  schec101                papaa101   \n",
       "\n",
       "  name of official scorer, if known  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data9 = EVdata.loc[data.inning==9]\n",
    "data92 = data9[abs(data9['vis score']-data9['home score'])<2]#9th inning with two outs\n",
    "x = data9['outs']\n",
    "y = data9['RBI on play']\n",
    "correlation = np.corrcoef(x, y)\n",
    "EVdata[\"outOrHit\"] = EVdata.apply(lambda row: 1 if \n",
    "                                (row[\"event type\"]==2 or \n",
    "                                row[\"event type\"]==3) else\n",
    "                                2 if \n",
    "                                row[\"event type\"]==20 else\n",
    "                                3 if\n",
    "                                row[\"event type\"]==21 else\n",
    "                                4 if\n",
    "                                row[\"event type\"]==22 else\n",
    "                                5 if\n",
    "                                row[\"event type\"]==23\n",
    "                                else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "ax.hist(EVdata.loc[data.outs==2].outOrHit.dropna(), facecolor='green')\n",
    "ax.set_xlabel(\"Event Value\\nFigure 2\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_xticks(np.arange(6))\n",
    "ax.set_title(\"Frequency of Event Values with 2 Outs\")\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure and axis\n",
    "fig, ax = plt.subplots(figsize=(4,12), nrows=3, ncols=1)\n",
    "for i in data.loc[data.inning==9].outs.unique():\n",
    "    EVdata.loc[(data.inning==9) & (data.outs==i)].outOrHit.hist(ax=ax[i])\n",
    "    ax[i].set_xlabel(\"Event Value\\nFigure 1\")\n",
    "    ax[i].set_ylabel(\"Frequency\")\n",
    "    ax[i].set_xticks(np.arange(6))\n",
    "    ax[i].set_title(\"Frequency of Event Values with {0} Outs\".format(i))\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "plt.suptitle(\"Frequency of Event Values with 0, 1, and 2 Outs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying To Make Some Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
